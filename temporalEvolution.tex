This sub section relates to
the ``LSTM network'' block in Fig. \ref{fi:overall}.

In our work, we represent a video as $n$
fixed-length segments ($n$ differs for videos of different lengths) with overlapping frames.  Each segment
is represented with a fused vector $c_{t}$. Therefore, each video can be represented as a vector time series.


Now each vector time series could be analyzed using traditional time series modeling techniques,
such as Auto Regressive Moving Average, to obtain features or model parameters that can describe the
vector time series.
But the main drawback of these methods is that they model current values of a series as a function of past values
and have finite dynamic response to time series input. Also they lack the ability to grasp the internal state
representations of a complex time series. RNNs maintain hidden layers with directed feedback connections, and hence,
have an infinite dynamic response. While training, it learns internal states of a sequence
and usually performs better in modeling complex dynamic temporal patterns of long sequences.


However, it is not ideal to train standard RNNs to solve problems,
which require learning of long-term temporal dependencies. This is because of the vanishing-gradient problem, which occurs
due to the exponential decay of gradient loss of the function with respect to time.

In practice, LSTM networks typically perform better in such cases.
LSTM networks are a special type of RNN, which include a ``memory cell'', and as the name suggests,
it can maintain a certain state in memory for longer periods of time.
It also has a set of control gates for controlling the removal or addition of information to the cell state.
This special architecture gives them the ability to capture longer-term dependencies. First, we revise the operation of an LSTM network.

The most important structure of an LSTM unit is its memory cell $c_{t}$, which preserves the state. Basic structure of an LSTM unit is shown in figure \ref{fi:lstmblock}. The memory cell is self connected, and it has three gates(multiplicative units), i.e., input gate, forget gate and
output gate, which are used to control how much to store, remove or output long range contextual information of a temporal sequence.

The detailed activation process of the memory cell and three gates, as shown in Fig. \ref{fi:lstmblock} is
illustrated as follows:


\begin{figure}
  \centering
  \input{figures/lstmblock}
  \caption{Long short-term memory (LSTM) block cell. Source \cite{Graves2008supervised}.}\label{fi:lstmblock}
\end{figure}

\begin{equation}
i^{t} = \sigma (W_{xi}x^t + W_{hi}h^{t-1} + W_{ci}c^{t-1} + b_{i})
\end{equation}
\begin{equation}
f^{t} = \sigma (W_{xf}x^t + W_{hf}h^{t-1} + W_{cf}c^{t-1} + b_{f})
\end{equation}
\begin{equation}
c^{t} = f^tc^{t-1} + i^ttanh(W_{xc}x^t + W_{hc}h^{t-1} + b_{c})
\end{equation}
\begin{equation}
o^{t} = \sigma (W_{xo}x^t + W_{ho}h^{t-1} + W_{co}c^{t-1} + b_{o})
\end{equation}
\begin{equation}
h^t = o^t\tanh(c^t)
\end{equation}

where $W$ is the connection weight between two units and $\sigma(\cdot)$ is the sigmoid function.

Since the LSTM network is used only for capturing the temporal dynamic patterns between sub actions, one LSTM layer is enough.
Our LSTM network is shown in Fig. \ref{fi:layers}. The network consists of an input layer, a 128 unit LSTM layer with 0.8 dropout, and
a fully connected softmax output layer. As we have a sequence of activities per classification, we use a many to one approach
for feeding the fused vectors to the network, as shown in Fig. \ref{fi:lstm}.

\begin{figure}
  \centering
  \input{figures/layers}
  \caption{A simple illustration of the LSTM network. The network consists of an input layer, a 128 unit LSTM layer with 0.8 dropout, and
a fully connected softmax output layer.}\label{fi:layers}
\end{figure}

\begin{figure}
  \centering
  \input{figures/lstm}
  \caption{The process of feeding fused vectors to the LSTM network. $c_{i}$ indicates the fused vector representing the $i_{th}$
  video segment.}\label{fi:lstm}
\end{figure}



